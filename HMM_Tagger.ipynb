{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eWE-ekY1j-wo"
      },
      "outputs": [],
      "source": [
        "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
        "%load_ext autoreload\n",
        "%aimport helpers, tests\n",
        "%autoreload 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pomegranate==0.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EfjVC_PmssD",
        "outputId": "b0af5e64-d4b2-4e6a-ebb5-3c9469f94901"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pomegranate==0.12.0\n",
            "  Downloading pomegranate-0.12.0.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.9.0b4 in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0) (1.3.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0) (3.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0) (1.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0) (6.0.1)\n",
            "Building wheels for collected packages: pomegranate\n",
            "  Building wheel for pomegranate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pomegranate: filename=pomegranate-0.12.0-cp310-cp310-linux_x86_64.whl size=12877635 sha256=2f1436e3bb5cab044689e88952daa2af190ed549c90857ee9f81a817a65c5e82\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/70/cb/9cdb862af960baf0fc3c2c461456ee721ef08a14b76c6935bb\n",
            "Successfully built pomegranate\n",
            "Installing collected packages: pomegranate\n",
            "Successfully installed pomegranate-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import python modules -- this cell needs to be run again if you make changes to any of the files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "from itertools import chain\n",
        "from collections import Counter, defaultdict\n",
        "from helpers import show_model, Dataset\n",
        "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
      ],
      "metadata": {
        "id": "xVx4jExLm2BZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Read and preprocess the dataset"
      ],
      "metadata": {
        "id": "XvmpKRHTn0ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset(\"tags-universal.txt\", \"brown-universal.txt\", train_test_split=0.8)\n",
        "\n",
        "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
        "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
        "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
        "\n",
        "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
        "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmXtYi2rnuiB",
        "outputId": "730bbbe4-9f9f-45d6-cc21-aa73d3dfecf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 57340 sentences in the corpus.\n",
            "There are 45872 sentences in the training set.\n",
            "There are 11468 sentences in the testing set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset Interface"
      ],
      "metadata": {
        "id": "tfDANvpOpEbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access (mostly) immutable references to the dataset through a simple interface provided through the Dataset class, which represents an iterable collection of sentences along with easy access to partitions of the data for training & testing. Review the reference below, then run and review the next few cells to make sure you understand the interface before moving on to the next step.\n",
        "\n",
        "    dataset-only Attributes:\n",
        "    training_set - reference to a Subset object containing the samples for training\n",
        "    testing_set - reference to a Subset object containing the samples for testing\n",
        "\n",
        "    Dataset & Subset Attributes:\n",
        "    sentences - a dictionary with an entry {sentence_key: Sentence()} for each sentence in the corpus\n",
        "    keys - an immutable ordered (not sorted) collection of the sentence_keys for the corpus\n",
        "    vocab - an immutable collection of the unique words in the corpus\n",
        "    tagset - an immutable collection of the unique tags in the corpus\n",
        "    X - returns an array of words grouped by sentences ((w11, w12, w13, ...), (w21, w22, w23, ...), ...)\n",
        "    Y - returns an array of tags grouped by sentences ((t11, t12, t13, ...), (t21, t22, t23, ...), ...)\n",
        "    N - returns the number of distinct samples (individual words or tags) in the dataset\n",
        "\n",
        "    Methods:\n",
        "    stream() - returns an flat iterable over all (word, tag) pairs across all sentences in the corpus\n",
        "    __iter__() - returns an iterable over the data as (sentence_key, Sentence()) pairs\n",
        "    __len__() - returns the nubmer of sentences in the dataset\n",
        "\n",
        "For example, consider a Subset, subset, of the sentences {\"s0\": Sentence((\"See\", \"Spot\", \"run\"), (\"VERB\", \"NOUN\", \"VERB\")), \"s1\": Sentence((\"Spot\", \"ran\"), (\"NOUN\", \"VERB\"))}. The subset will have these attributes:\n",
        "\n",
        "    subset.keys == {\"s1\", \"s0\"}  # unordered\n",
        "    subset.vocab == {\"See\", \"run\", \"ran\", \"Spot\"}  # unordered\n",
        "    subset.tagset == {\"VERB\", \"NOUN\"}  # unordered\n",
        "    subset.X == ((\"Spot\", \"ran\"), (\"See\", \"Spot\", \"run\"))  # order matches .keys\n",
        "    subset.Y == ((\"NOUN\", \"VERB\"), (\"VERB\", \"NOUN\", \"VERB\"))  # order matches .keys\n",
        "    subset.N == 7  # there are a total of seven observations over all sentences\n",
        "    len(subset) == 2  # because there are two sentences\n",
        "\n",
        "Sentences\n",
        "\n",
        "  Dataset.sentences is a dictionary of all sentences in the training corpus, each keyed to a unique sentence identifier. Each Sentence is itself an object with two attributes: a tuple of the words in the sentence named words and a tuple of the tag corresponding to each word named tags."
      ],
      "metadata": {
        "id": "ZNGDwKrZqInG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = 'b100-38532'\n",
        "print(\"Sentence: {}\".format(key))\n",
        "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
        "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHyS7XPmq2Cw",
        "outputId": "5a62305b-1979-44e9-ff37-b159d9d5f348"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: b100-38532\n",
            "words:\n",
            "\t('Perhaps', 'it', 'was', 'right', ';', ';')\n",
            "tags:\n",
            "\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting Unique Elements"
      ],
      "metadata": {
        "id": "uqzP25xerE_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access the list of unique words (the dataset vocabulary) via Dataset.vocab and the unique list of tags via Dataset.tagset."
      ],
      "metadata": {
        "id": "AVmrKzz2rLNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
        "      .format(data.N, len(data.vocab)))\n",
        "print(\"There are {} samples of {} unique words in the training set.\"\n",
        "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
        "print(\"There are {} samples of {} unique words in the testing set.\"\n",
        "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
        "print(\"There are {} words in the test set that are missing in the training set.\"\n",
        "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
        "\n",
        "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
        "       \"The number of training + test samples should sum to the total number of samples\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hia5GHzvq8f2",
        "outputId": "80b02ce9-4899-4522-bffe-a39901cc7231"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
            "There are 928458 samples of 50536 unique words in the training set.\n",
            "There are 232734 samples of 25112 unique words in the testing set.\n",
            "There are 5521 words in the test set that are missing in the training set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing word and tag Sequences\n",
        "\n",
        "The Dataset.X and Dataset.Y attributes provide access to ordered collections of matching word and tag sequences for each sentence in the dataset."
      ],
      "metadata": {
        "id": "26kGrgU_r8Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing words with Dataset.X and tags with Dataset.Y\n",
        "for i in range(2):\n",
        "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
        "    print()\n",
        "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaqIqxkGrVvy",
        "outputId": "6bbba753-1b01-4028-a4c5-38e0238284ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
            "\n",
            "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
            "\n",
            "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing (word, tag) Samples\n",
        "\n",
        "The Dataset.stream() method returns an iterator that chains together every pair of (word, tag) entries across all sentences in the entire corpus."
      ],
      "metadata": {
        "id": "jYCxDVBjsR4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use Dataset.stream() (word, tag) samples for the entire corpus\n",
        "print(\"\\nStream (word, tag) pairs:\\n\")\n",
        "for i, pair in enumerate(data.stream()):\n",
        "    print(\"\\t\", pair)\n",
        "    if i > 5: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA-gZ_9HsB4Q",
        "outputId": "4b09d8c7-2a92-4a1f-f436-0c48215f0113"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stream (word, tag) pairs:\n",
            "\n",
            "\t ('Mr.', 'NOUN')\n",
            "\t ('Podger', 'NOUN')\n",
            "\t ('had', 'VERB')\n",
            "\t ('thanked', 'VERB')\n",
            "\t ('him', 'PRON')\n",
            "\t ('gravely', 'ADV')\n",
            "\t (',', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Build a Most Frequent Class tagger"
      ],
      "metadata": {
        "id": "lAGvKdlWsiff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION: Pair Counts"
      ],
      "metadata": {
        "id": "7q3RvKUtsrsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pair_counts(sequences_A, sequences_B):\n",
        "    \"\"\"Return a dictionary keyed to each unique value in the first sequence list\n",
        "    that counts the number of occurrences of the corresponding value from the\n",
        "    second sequences list.\n",
        "\n",
        "    For example, if sequences_A is tags and sequences_B is the corresponding\n",
        "    words, then if 1244 sequences contain the word \"time\" tagged as a NOUN, then\n",
        "    you should return a dictionary such that pair_counts[NOUN][time] == 1244\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # TODO: Finish this function!\n",
        "    pair_counts = defaultdict(Counter)\n",
        "    assert len(sequences_A) == len(sequences_B), \"Two sequence length should be same!\"\n",
        "    for i in range(len(sequences_A)):\n",
        "        for t, w in zip(sequences_A[i],sequences_B[i]):\n",
        "            pair_counts[t][w] += 1\n",
        "    return pair_counts\n",
        "\n",
        "# Calculate C(t_i, w_i)\n",
        "emission_counts = pair_counts(data.Y,data.X) # TODO: YOUR CODE HERE)\n",
        "\n",
        "assert len(emission_counts) == 12, \\\n",
        "       \"Uh oh. There should be 12 tags in your dictionary.\"\n",
        "assert max(emission_counts[\"NOUN\"], key=emission_counts[\"NOUN\"].get) == 'time', \\\n",
        "       \"Hmmm...'time' is expected to be the most common NOUN.\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jJuwZdxPsbKz",
        "outputId": "537fca20-7389-46af-bfcc-ae063abf63d7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION: Most Frequent Class Tagger"
      ],
      "metadata": {
        "id": "xJe8w6z798CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
        "from collections import namedtuple\n",
        "\n",
        "FakeState = namedtuple(\"FakeState\", \"name\")\n",
        "\n",
        "class MFCTagger:\n",
        "    # NOTE: You should not need to modify this class or any of its methods\n",
        "    missing = FakeState(name=\"<MISSING>\")\n",
        "\n",
        "    def __init__(self, table):\n",
        "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
        "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
        "\n",
        "    def viterbi(self, seq):\n",
        "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
        "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
        "\n",
        "# TODO: calculate the frequency of each tag being assigned to each word (hint: similar, but not\n",
        "# the same as the emission probabilities) and use it to fill the mfc_table\n",
        "\n",
        "word_counts = pair_counts(data.training_set.X,data.training_set.Y)\n",
        "\n",
        "mfc_table = dict()\n",
        "for word, tags in word_counts.items():\n",
        "    mfc_table[word] = max(tags.items(), key=lambda x: x[1])[0]"
      ],
      "metadata": {
        "id": "SV-9u9kl0vQS"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #DO NOT MODIFY BELOW THIS LINE\n",
        "mfc_model = MFCTagger(mfc_table) # Create a Most Frequent Class tagger instance\n",
        "\n",
        "assert len(mfc_table) == len(data.training_set.vocab), \"\"\n",
        "assert all(k in data.training_set.vocab for k in mfc_table.keys()), \"\"\n",
        "assert sum(int(k not in mfc_table) for k in data.testing_set.vocab) == 5521, \"\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QkW_kbYo_LIV",
        "outputId": "6691711f-5453-424b-ac74-e0b1ba5644a1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making Predictions with a Model"
      ],
      "metadata": {
        "id": "sMAOoAL7AwGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_unknown(sequence):\n",
        "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
        "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
        "    during computation.\n",
        "    \"\"\"\n",
        "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
        "\n",
        "def simplify_decoding(X, model):\n",
        "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
        "    _, state_path = model.viterbi(replace_unknown(X))\n",
        "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
      ],
      "metadata": {
        "id": "6cQ2vxFiAESz"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in data.testing_set.keys[:10]:\n",
        "    print(\"Sentence Key: {}\\n\".format(key))\n",
        "    print(\"Predicted labels:\\n-----------------\")\n",
        "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
        "    print()\n",
        "    print(\"Actual labels:\\n--------------\")\n",
        "    print(data.sentences[key].tags)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gusVvRKnBKuU",
        "outputId": "3e8e320b-62b7-4781-8034-4eb4496303a6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Key: b100-28144\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-23146\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-35462\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', '<MISSING>', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADV', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-37008\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-18135\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', '<MISSING>', 'VERB', 'VERB', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'VERB', 'VERB', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-20386\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.', 'ADJ', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', '.', 'CONJ', 'ADJ', 'ADJ', 'NOUN', 'VERB', '.', 'PRT', 'VERB', 'DET', '<MISSING>', 'NOUN', 'CONJ', 'PRT', 'VERB', 'PRON', 'ADP', 'ADV', 'ADP', 'ADJ', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.', 'ADJ', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', '.', 'CONJ', 'ADJ', 'ADJ', 'NOUN', 'VERB', '.', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', 'CONJ', 'PRT', 'VERB', 'PRON', 'ADV', 'ADV', 'ADP', 'ADJ', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-7406\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['VERB', 'VERB', 'ADP', 'ADJ', 'DET', '<MISSING>', 'NOUN', '.', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('VERB', 'VERB', 'ADP', 'ADJ', 'DET', 'NOUN', 'NOUN', '.', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-49373\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['NOUN', 'NOUN', 'VERB', '.', 'VERB', 'DET', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'NOUN', 'VERB', 'DET', 'PRT', 'ADP', 'DET', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('NOUN', 'NOUN', 'VERB', '.', 'VERB', 'DET', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'NOUN', 'VERB', 'PRON', 'PRT', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-23853\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'ADP', 'NOUN', 'ADV', 'VERB', 'ADP', 'PRON', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'PRT', 'VERB', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'ADP', 'NOUN', 'ADV', 'VERB', 'ADP', 'PRON', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'PRT', 'VERB', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-56067\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['<MISSING>', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'DET', 'NOUN', '.', 'ADV', 'NUM', 'ADP', 'VERB', 'NOUN', '.', 'ADV', 'ADP', 'VERB', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'VERB', 'ADV', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('ADV', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'DET', 'NOUN', '.', 'ADV', 'NOUN', 'PRON', 'VERB', 'NOUN', '.', 'ADV', 'ADP', 'VERB', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'VERB', 'ADV', '.')\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Model Accuracy"
      ],
      "metadata": {
        "id": "ojietjBZBwAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below will evaluate the accuracy of the MFC tagger on the collection of all sentences from a text corpus."
      ],
      "metadata": {
        "id": "FUQSdiUMBzEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(X, Y, model):\n",
        "    \"\"\"Calculate the prediction accuracy by using the model to decode each sequence\n",
        "    in the input X and comparing the prediction with the true labels in Y.\n",
        "\n",
        "    The X should be an array whose first dimension is the number of sentences to test,\n",
        "    and each element of the array should be an iterable of the words in the sequence.\n",
        "    The arrays X and Y should have the exact same shape.\n",
        "\n",
        "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
        "    Y = [(), (), ...]\n",
        "    \"\"\"\n",
        "    correct = total_predictions = 0\n",
        "    for observations, actual_tags in zip(X, Y):\n",
        "\n",
        "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
        "        # raises an error (for example, if a test sentence contains a word that\n",
        "        # is out of vocabulary for the training set). Any exception counts the\n",
        "        # full sentence as an error (which makes this a conservative estimate).\n",
        "        try:\n",
        "            most_likely_tags = simplify_decoding(observations, model)\n",
        "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
        "        except:\n",
        "            pass\n",
        "        total_predictions += len(observations)\n",
        "    return correct / total_predictions"
      ],
      "metadata": {
        "id": "0gOl1TwIBUIU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the accuracy of the MFC tagger"
      ],
      "metadata": {
        "id": "Vw_qoEZOCRxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
        "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
        "\n",
        "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
        "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n",
        "\n",
        "assert mfc_training_acc >= 0.955, \"Uh oh. Your MFC accuracy on the training set doesn't look right.\"\n",
        "assert mfc_testing_acc >= 0.925, \"Uh oh. Your MFC accuracy on the testing set doesn't look right.\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "F8gAHkOvCNQS",
        "outputId": "7d8f72d6-9afa-4199-d538-ac37995dfcac"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy mfc_model: 95.72%\n",
            "testing accuracy mfc_model: 93.01%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Build an HMM tagger"
      ],
      "metadata": {
        "id": "sze-oCIHCwEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_counts(sequences):\n",
        "    \"\"\"Return a dictionary keyed to each unique value in the input sequence list that\n",
        "    counts the number of occurrences of the value in the sequences list. The sequences\n",
        "    collection should be a 2-dimensional array.\n",
        "\n",
        "    For example, if the tag NOUN appears 275558 times over all the input sequences,\n",
        "    then you should return a dictionary such that your_unigram_counts[NOUN] == 275558.\n",
        "    \"\"\"\n",
        "    unigram = [tag for seq in sequences for tag in seq]\n",
        "\n",
        "    return Counter(unigram)\n",
        "\n",
        "# TODO: call unigram_counts with a list of tag sequences from the training set\n",
        "tag_unigrams = unigram_counts(data.training_set.Y) # TODO: YOUR CODE HERE)\n",
        "\n",
        "assert set(tag_unigrams.keys()) == data.training_set.tagset, \\\n",
        "       \"Uh oh. It looks like your tag counts doesn't include all the tags!\"\n",
        "assert min(tag_unigrams, key=tag_unigrams.get) == 'X', \\\n",
        "       \"Hmmm...'X' is expected to be the least common class\"\n",
        "assert max(tag_unigrams, key=tag_unigrams.get) == 'NOUN', \\\n",
        "       \"Hmmm...'NOUN' is expected to be the most common class\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cqASLUzeCwjB",
        "outputId": "4fd2fc1f-c2fa-4f2c-c59d-ee8d3c7a7e1b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_counts(sequences):\n",
        "    \"\"\"Return a dictionary keyed to each unique PAIR of values in the input sequences\n",
        "    list that counts the number of occurrences of pair in the sequences list. The input\n",
        "    should be a 2-dimensional array.\n",
        "\n",
        "    For example, if the pair of tags (NOUN, VERB) appear 61582 times, then you should\n",
        "    return a dictionary such that your_bigram_counts[(NOUN, VERB)] == 61582\n",
        "    \"\"\"\n",
        "\n",
        "    bigram = [(seq[tag],seq[tag+1]) for seq in sequences for tag in range(len(seq) - 1)]\n",
        "    return Counter(bigram)\n",
        "\n",
        "# TODO: call bigram_counts with a list of tag sequences from the training set\n",
        "tag_bigrams = bigram_counts(data.training_set.Y)# TODO: YOUR CODE HERE)\n",
        "\n",
        "assert len(tag_bigrams) == 144, \\\n",
        "       \"Uh oh. There should be 144 pairs of bigrams (12 tags x 12 tags)\"\n",
        "assert min(tag_bigrams, key=tag_bigrams.get) in [('X', 'NUM'), ('PRON', 'X')], \\\n",
        "       \"Hmmm...The least common bigram should be one of ('X', 'NUM') or ('PRON', 'X').\"\n",
        "assert max(tag_bigrams, key=tag_bigrams.get) in [('DET', 'NOUN')], \\\n",
        "       \"Hmmm...('DET', 'NOUN') is expected to be the most common bigram.\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pe5rOVoTERFf",
        "outputId": "63b495b7-2947-425a-fdc5-82dfe221b9ab"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION: Sequence Starting Counts"
      ],
      "metadata": {
        "id": "y-e2xT77Ijz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def starting_counts(sequences):\n",
        "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
        "    that counts the number of occurrences where that value is at the beginning of\n",
        "    a sequence.\n",
        "\n",
        "    For example, if 8093 sequences start with NOUN, then you should return a\n",
        "    dictionary such that your_starting_counts[NOUN] == 8093\n",
        "    \"\"\"\n",
        "    starting = defaultdict()\n",
        "    for seq in sequences:\n",
        "        starting[seq[0]] = starting.get(seq[0], 0) + 1\n",
        "    return starting\n",
        "\n",
        "\n",
        "# TODO: Calculate the count of each tag starting a sequence\n",
        "tag_starts = starting_counts(data.training_set.Y)# TODO: YOUR CODE HERE)\n",
        "\n",
        "assert len(tag_starts) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
        "assert min(tag_starts, key=tag_starts.get) == 'X', \"Hmmm...'X' is expected to be the least common starting bigram.\"\n",
        "assert max(tag_starts, key=tag_starts.get) == 'DET', \"Hmmm...'DET' is expected to be the most common starting bigram.\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2jKqYbgpGLXi",
        "outputId": "e59056da-256c-453f-d530-7aabaf0b5784"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION: Sequence Ending Counts"
      ],
      "metadata": {
        "id": "7rapeF9XLwlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ending_counts(sequences):\n",
        "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
        "    that counts the number of occurrences where that value is at the end of\n",
        "    a sequence.\n",
        "\n",
        "    For example, if 18 sequences end with DET, then you should return a\n",
        "    dictionary such that your_starting_counts[DET] == 18\n",
        "    \"\"\"\n",
        "    ending = defaultdict()\n",
        "    for seq in sequences:\n",
        "        ending[seq[-1]] = ending.get(seq[-1], -1) + 1\n",
        "    return ending\n",
        "\n",
        "# TODO: Calculate the count of each tag ending a sequence\n",
        "tag_ends = ending_counts(data.training_set.Y)# TODO: YOUR CODE HERE)\n",
        "\n",
        "assert len(tag_ends) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
        "assert min(tag_ends, key=tag_ends.get) in ['X', 'CONJ'], \"Hmmm...'X' or 'CONJ' should be the least common ending bigram.\"\n",
        "assert max(tag_ends, key=tag_ends.get) == '.', \"Hmmm...'.' is expected to be the most common ending bigram.\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "prDO-VQhGMFh",
        "outputId": "89df5a20-0b81-47b5-c081-de68e65ba2a4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION: Basic HMM Tagger"
      ],
      "metadata": {
        "id": "pSIlSohiMoAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
        "\n",
        "# TODO: create states with emission probability distributions P(word | tag) and add to the model\n",
        "# (Hint: you may need to loop & create/add new states)\n",
        "\n",
        "emission_counts = pair_counts(data.training_set.Y , data.training_set.X)\n",
        "# Initialize a dictionary to store the states object by tag.\n",
        "states = dict()\n",
        "\n",
        "# Loop over all the tagset and create a state for each tags\n",
        "for tag in data.training_set.tagset:\n",
        "\n",
        "    # Create a dict to store the emission distribution for the tag\n",
        "    emissions_distribution = dict()\n",
        "\n",
        "    # Compute the emission distribution P(w|t) = C(t,w) / C(t) and store it in a dictionary by word\n",
        "    for word in emission_counts[tag]:\n",
        "        emissions_distribution[word] = emission_counts[tag][word] / tag_unigrams[tag]\n",
        "\n",
        "    # Create a discrete distribution and a state for the current tag\n",
        "    tag_emissions = DiscreteDistribution(emissions_distribution)\n",
        "    tag_state = State(tag_emissions, name=tag)\n",
        "    # Store the created state in a dictionary\n",
        "    states[tag]=tag_state\n",
        "\n",
        "basic_model.add_states([ems for ems in states.values()])\n",
        "\n",
        "# add edges between hidden states for the observed transition frequencies P(tag_i | tag_i-1)\n",
        "for ti, tj in tag_bigrams.keys():\n",
        "    # Compute the transition probability P(tj|ti)= C(tj,ti) / C(ti)\n",
        "    transitionProbability = tag_bigrams[(ti,tj)] / tag_unigrams[ti]\n",
        "    basic_model.add_transition(states[ti], states[tj] , transitionProbability)\n",
        "\n",
        "# Add an edge from start state to each tag.\n",
        "for tag in data.training_set.tagset:\n",
        "    # Compute the transition probability P(t|start)= C(start,t) / C(start)\n",
        "    transitionProbability = tag_starts[tag] / len(tag_starts)\n",
        "    basic_model.add_transition(basic_model.start, states[tag], transitionProbability)\n",
        "\n",
        "# Add an edge from each tag to the end state\n",
        "for tag in data.training_set.tagset:\n",
        "    # Compute the transition probability P(end|t) = C(t,end) / C(t)\n",
        "    transitionProbability = tag_ends[tag] / tag_unigrams[tag]\n",
        "    basic_model.add_transition(states[tag], basic_model.end , transitionProbability)\n",
        "\n",
        "# NOTE: YOU SHOULD NOT NEED TO MODIFY ANYTHING BELOW THIS LINE\n",
        "# finalize the model\n",
        "basic_model.bake()\n",
        "\n",
        "assert all(tag in set(s.name for s in basic_model.states) for tag in data.training_set.tagset), \\\n",
        "       \"Every state in your network should use the name of the associated tag, which must be one of the training set tags.\"\n",
        "assert basic_model.edge_count() == 168, \\\n",
        "       (\"Your network should have an edge from the start node to each state, one edge between every \" +\n",
        "        \"pair of tags (states), and an edge from each state to the end node.\")\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>')\n",
        "\n",
        "# NOTE: YOU SHOULD NOT NEED TO MODIFY ANYTHING BELOW THIS LINE\n",
        "# finalize the model\n",
        "basic_model.bake()\n",
        "\n",
        "assert all(tag in set(s.name for s in basic_model.states) for tag in data.training_set.tagset), \\\n",
        "       \"Every state in your network should use the name of the associated tag, which must be one of the training set tags.\"\n",
        "assert basic_model.edge_count() == 168, \\\n",
        "       (\"Your network should have an edge from the start node to each state, one edge between every \" +\n",
        "        \"pair of tags (states), and an edge from each state to the end node.\")\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vKmEfaPOLRfL",
        "outputId": "58b73451-f7b6-4726-e997-8ea25bc92556"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
        "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
        "\n",
        "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
        "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))\n",
        "\n",
        "assert hmm_training_acc > 0.97, \"Uh oh. Your HMM accuracy on the training set doesn't look right.\"\n",
        "assert hmm_testing_acc > 0.955, \"Uh oh. Your HMM accuracy on the testing set doesn't look right.\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct! Congratulations, you\\'ve finished the project.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "2nHmuh9IPPOx",
        "outputId": "9e0367c2-86a6-44d2-ffef-1e050527cd7d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy basic hmm model: 97.54%\n",
            "testing accuracy basic hmm model: 95.95%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct! Congratulations, you've finished the project."
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Decoding Sequences with the HMM Tagger"
      ],
      "metadata": {
        "id": "MsEW9xqDQCvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key in data.testing_set.keys[:10]:\n",
        "    print(\"Sentence Key: {}\\n\".format(key))\n",
        "    print(\"Predicted labels:\\n-----------------\")\n",
        "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
        "    print()\n",
        "    print(\"Actual labels:\\n--------------\")\n",
        "    print(data.sentences[key].tags)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4YwWjYhPqon",
        "outputId": "af24465c-26e5-4a32-e80f-91c91bc2b692"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Key: b100-28144\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-23146\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-35462\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-37008\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-18135\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', 'PRON', 'VERB', 'VERB', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'VERB', 'VERB', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-20386\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.', 'ADJ', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', '.', 'CONJ', 'ADJ', 'ADJ', 'NOUN', 'VERB', '.', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', 'CONJ', 'PRT', 'VERB', 'PRON', 'ADV', 'ADV', 'ADP', 'ADJ', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.', 'ADJ', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', '.', 'CONJ', 'ADJ', 'ADJ', 'NOUN', 'VERB', '.', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', 'CONJ', 'PRT', 'VERB', 'PRON', 'ADV', 'ADV', 'ADP', 'ADJ', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-7406\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['VERB', 'VERB', 'ADP', 'VERB', 'DET', 'ADJ', 'NOUN', '.', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('VERB', 'VERB', 'ADP', 'ADJ', 'DET', 'NOUN', 'NOUN', '.', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-49373\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['NOUN', 'NOUN', 'VERB', '.', 'VERB', 'DET', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'NOUN', 'VERB', 'PRON', 'PRT', 'ADP', 'DET', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('NOUN', 'NOUN', 'VERB', '.', 'VERB', 'DET', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'NOUN', 'VERB', 'PRON', 'PRT', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-23853\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'ADP', 'NOUN', 'ADV', 'VERB', 'ADP', 'PRON', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'PRT', 'VERB', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'ADP', 'NOUN', 'ADV', 'VERB', 'ADP', 'PRON', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'PRT', 'VERB', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-56067\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['DET', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'DET', 'NOUN', '.', 'ADV', 'NUM', 'ADP', 'VERB', 'NOUN', '.', 'ADV', 'ADP', 'VERB', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'VERB', 'ADV', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('ADV', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'DET', 'NOUN', '.', 'ADV', 'NOUN', 'PRON', 'VERB', 'NOUN', '.', 'ADV', 'ADP', 'VERB', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'VERB', 'ADV', '.')\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: [Optional] Improving model performance"
      ],
      "metadata": {
        "id": "Qg09mFm0Qf70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.corpus import brown\n",
        "\n",
        "nltk.download('brown')\n",
        "training_corpus = nltk.corpus.brown\n",
        "training_corpus.tagged_sents()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Hqt8XCQK2v",
        "outputId": "d034870c-ac4e-4aa6-a5c0-2f46286d1201"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'AT'),\n",
              " ('Fulton', 'NP-TL'),\n",
              " ('County', 'NN-TL'),\n",
              " ('Grand', 'JJ-TL'),\n",
              " ('Jury', 'NN-TL'),\n",
              " ('said', 'VBD'),\n",
              " ('Friday', 'NR'),\n",
              " ('an', 'AT'),\n",
              " ('investigation', 'NN'),\n",
              " ('of', 'IN'),\n",
              " (\"Atlanta's\", 'NP$'),\n",
              " ('recent', 'JJ'),\n",
              " ('primary', 'NN'),\n",
              " ('election', 'NN'),\n",
              " ('produced', 'VBD'),\n",
              " ('``', '``'),\n",
              " ('no', 'AT'),\n",
              " ('evidence', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('that', 'CS'),\n",
              " ('any', 'DTI'),\n",
              " ('irregularities', 'NNS'),\n",
              " ('took', 'VBD'),\n",
              " ('place', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCsbf1tdQ-Xo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}